{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick a website and describe your objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Browse through different sites and pick on to scrape. Check the\"Project ldeas\" section for inspiration.\n",
    "\n",
    "- ldentify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n",
    "\n",
    "- Summarize your project ide and outline your strategy in a Juptyer notebook. Use the\"New' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Outline:\n",
    "\n",
    "- We're going to scrapt https://github.com/topics\n",
    "\n",
    "- We'll get a list of topics. For each topic, we'll get topic title,\n",
    "topic page URL and topic description.\n",
    "\n",
    "- For each topic, we'll get the top 25 repositories in the topic\n",
    "from the topic page.\n",
    "\n",
    "- For each repository, we'll grab the repo name, username, stars and \n",
    "repo URL\n",
    "\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "```\n",
    "        Repo Name, Username, Stars, Repo URL\n",
    "        three.js,mrdoob, 69700,https://github.com/mrdoob/three.js\n",
    "        libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the requests library to download web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_url = 'https://github.com/topics'\n",
    "response = requests.get(topics_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text\n",
    "# page_contents[:200]\n",
    "\n",
    "with open('webpage.html', 'w', encoding='utf-16') as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Beautiful Soup to parse and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0eb88604aa9a2b11beeb850e528ceda8abb9c243508b04548adf4aff4e31bae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
